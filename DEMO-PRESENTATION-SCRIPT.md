# OCSF Security Data Lake Demo - Presentation Script

**Duration**: 15-20 minutes
**Audience**: Security teams, data engineers, executives
**Goal**: Demonstrate OCSF standardization + modern data lake architecture

---

## ðŸ“‹ Pre-Demo Checklist (5 minutes before)

### Infrastructure Check
```bash
# 1. Verify all containers running
docker-compose ps

# Expected: minio, dremio, postgres, jupyter all "Up"
```

### Data Verification
```bash
# 2. Verify data exists
docker exec zeek-demo-minio mc ls local/zeek-data/network-activity-ocsf/ --recursive

# Expected: 9.1MiB data.parquet file
```

### Dremio Access
- [ ] Open http://localhost:9047 in browser
- [ ] Login with credentials (do NOT show password to audience)
- [ ] Have 4-5 query tabs pre-opened
- [ ] Paste queries (but don't run yet)
- [ ] Test one query to verify it works

### Browser Setup
- [ ] Close unnecessary tabs
- [ ] Zoom browser to 125-150% for visibility
- [ ] Clear any previous query results
- [ ] Have SQL editor ready

---

## ðŸŽ¬ Demo Script

---

## SECTION 1: The Problem (3 minutes)

### Opening Statement
*"Good morning/afternoon everyone. Today I want to show you how we're solving one of the biggest challenges in security operations: data standardization and vendor lock-in."*

### The Current State Pain Points

**Talking Points:**
1. **Proprietary Formats**
   - "Security teams today deal with dozens of different log formats"
   - "Every vendor has their own schema, field names, and structure"
   - "Show of hands: How many different SIEM or security tools do you have?"

2. **Integration Nightmares**
   - "Each new tool requires custom parsers and integration work"
   - "Analysts waste time translating between formats"
   - "Correlation across vendors is nearly impossible"

3. **Vendor Lock-in**
   - "Once you commit to a vendor's format, you're stuck"
   - "Migration means rewriting all your queries, rules, and dashboards"
   - "Your institutional knowledge is trapped in proprietary schemas"

### The Vision

*"What if we could standardize security data the same way HTTP standardized web communication? That's exactly what OCSF does."*

**Key Point**: OCSF = Linux Foundation standard for security data

---

## SECTION 2: The Solution - OCSF (2 minutes)

### What is OCSF?

**Talking Points:**
- **Open Cybersecurity Schema Framework**
- Linux Foundation project (same org as Kubernetes, Linux)
- Backed by AWS, Splunk, Cloudflare, and 40+ companies
- Open source, vendor-neutral standard

### Why OCSF Matters

**The Analogy:**
*"Think of OCSF like USB-C. Before USB-C, every phone had a different charger. Now, one cable works everywhere. OCSF does the same thing for security data."*

**Benefits:**
1. **Vendor Neutrality** - Switch tools without rewriting everything
2. **Interoperability** - Tools from different vendors work together
3. **Future-Proof** - New tools can read your existing data
4. **Community-Driven** - Not controlled by any single vendor

### Show the Standard

*"Let me show you what this looks like in practice..."*

**[Open OCSF documentation in browser - optional]**
- Navigate to https://schema.ocsf.io
- Show class hierarchy briefly
- Point out Network Activity (class 4001)

*"We're using class 4001 - Network Activity - which standardizes network logs from any source."*

---

## SECTION 3: Live Demo - The Data (8 minutes)

### Demo Introduction

*"I've loaded 100,000 real network events from Zeek - an open-source network monitoring tool. But instead of keeping them in Zeek's proprietary format, I've transformed them to OCSF. Let me show you what that enables..."*

**[Switch to Dremio browser window]**

*"I'm using Dremio as my query engine, connected to MinIO for S3-compatible storage. The data is stored in Parquet format for optimal performance."*

---

### Query 1: Verify Data Load (30 seconds)

**Purpose**: Show the data is accessible and the scale

**Pre-paste this in Query Tab 1:**
```sql
SELECT COUNT(*) as total_records
FROM minio."zeek-data"."network-activity-ocsf"
```

**Say while typing/before running:**
*"First, let's verify our data is loaded. Notice I'm querying directly using the full path - this bypasses the UI folder navigation and goes straight to the data."*

**[Click Run]**

**Talking Points (while query runs):**
- "This is querying 100,000 security events"
- "Stored in columnar Parquet format"
- "Running on S3-compatible object storage"

**When results appear:**
*"There we go - 100,000 records, queried in under a second. That's the power of modern data lake architecture."*

---

### Query 2: OCSF Field Structure (1 minute)

**Purpose**: Show OCSF compliance and field naming

**Pre-paste this in Query Tab 2:**
```sql
SELECT
  class_uid,
  class_name,
  category_uid,
  category_name,
  activity_name,
  metadata_product_vendor_name,
  metadata_product_name,
  src_endpoint_ip,
  dst_endpoint_ip,
  connection_info_protocol_name,
  traffic_bytes_in,
  traffic_bytes_out
FROM minio."zeek-data"."network-activity-ocsf"
LIMIT 5
```

**Say before running:**
*"Now let's look at the actual OCSF schema. I'm going to select a few key fields to show you the structure."*

**[Click Run]**

**Talking Points (while showing results):**

Point to specific fields:

1. **class_uid / class_name**
   - "These identify the event type - 4001 is Network Activity"
   - "Every OCSF tool knows what class 4001 means"

2. **metadata fields**
   - "These tell us the data came from Zeek"
   - "But the actual fields are standardized"

3. **endpoint fields**
   - "src_endpoint_ip, dst_endpoint_ip - these are OCSF standard names"
   - "In Zeek's native format, they're called id.orig_h and id.resp_h"
   - "In Cisco logs, they're different. In Palo Alto, different again."
   - "With OCSF, they're all the same: src_endpoint_ip and dst_endpoint_ip"

4. **traffic fields**
   - "traffic_bytes_in, traffic_bytes_out - standardized metrics"
   - "Any OCSF-compatible tool can read these"

**Key Message:**
*"This standardization means we can switch from Zeek to Suricata, or add Palo Alto logs, and our queries still work. That's the power of OCSF."*

---

### Query 3: Security Analysis (2 minutes)

**Purpose**: Show a real security use case

**Pre-paste this in Query Tab 3:**
```sql
SELECT
  activity_name,
  COUNT(*) as event_count,
  ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage,
  SUM(traffic_bytes_in + traffic_bytes_out) as total_traffic
FROM minio."zeek-data"."network-activity-ocsf"
GROUP BY activity_name
ORDER BY event_count DESC
```

**Say before running:**
*"Let's do some actual security analysis. What types of network activity are we seeing in our environment?"*

**[Click Run]**

**Talking Points (when results appear):**

*"Look at this breakdown:"*
- "30% is generic traffic"
- "25% HTTP traffic"
- "25% SSL/TLS encrypted traffic"
- "11% DNS queries"
- "4% SSH connections"

*"This gives us immediate visibility into our network baseline. Notice how fast this aggregated across 100,000 records - less than a second."*

**Security Insight:**
*"In a real scenario, if we suddenly see a spike in SSH traffic or unusual protocol distribution, that's an indicator for investigation. OCSF makes this kind of baseline analysis trivial."*

---

### Query 4: Egress Traffic Analysis (2 minutes)

**Purpose**: Show advanced security correlation

**Pre-paste this in Query Tab 4:**
```sql
SELECT
  src_endpoint_ip,
  dst_endpoint_ip,
  activity_name,
  connection_info_protocol_name as protocol,
  COUNT(*) as connection_count,
  SUM(traffic_bytes_out) as total_egress_bytes,
  ROUND(AVG(traffic_bytes_out), 2) as avg_bytes_per_connection
FROM minio."zeek-data"."network-activity-ocsf"
WHERE
  src_endpoint_is_local = true
  AND dst_endpoint_is_local = false
  AND traffic_bytes_out > 0
GROUP BY
  src_endpoint_ip,
  dst_endpoint_ip,
  activity_name,
  connection_info_protocol_name
ORDER BY total_egress_bytes DESC
LIMIT 20
```

**Say before running:**
*"Now let's look at a critical security use case: egress traffic monitoring - data leaving our network."*

**Explain the query:**
- "I'm filtering where source is local and destination is external"
- "This shows potential data exfiltration patterns"
- "We're aggregating by source IP, destination, and protocol"

**[Click Run]**

**Talking Points (when results appear):**

*"Here we see the top 20 internal hosts sending data externally. Notice:"*
- "Who's talking to whom"
- "What protocols they're using"
- "How much data is being transferred"

*"In a real security operation, unusual egress patterns here would trigger investigation. Is this backup traffic? Cloud sync? Or potential data theft?"*

**OCSF Benefit:**
*"The key point: these OCSF fields - src_endpoint_is_local, dst_endpoint_is_local - work the same whether the data comes from Zeek, Suricata, firewall logs, or cloud network logs. Write the query once, use it everywhere."*

---

### Query 5: Performance Demonstration (1 minute)

**Purpose**: Show sub-second performance on complex queries

**Pre-paste this in Query Tab 5:**
```sql
SELECT
  src_endpoint_ip,
  COUNT(DISTINCT dst_endpoint_ip) as unique_destinations,
  COUNT(DISTINCT dst_endpoint_port) as unique_ports,
  COUNT(*) as total_connections,
  SUM(traffic_bytes_in + traffic_bytes_out) as total_traffic,
  ROUND(AVG(CAST(duration AS DOUBLE)), 2) as avg_duration_ms
FROM minio."zeek-data"."network-activity-ocsf"
GROUP BY src_endpoint_ip
HAVING COUNT(*) > 100
ORDER BY total_connections DESC
LIMIT 20
```

**Say before running:**
*"Finally, let me show you performance. This is a complex aggregation - multiple COUNT DISTINCT operations, SUMs, filtering. On 100,000 records."*

**[Click Run]**

**Timing:**
*"Watch the execution time... [wait for results] ...there we go. Sub-second response on a complex multi-dimensional aggregation."*

**Explain results:**
*"This shows our busiest internal hosts:"*
- "How many unique destinations they connected to"
- "How many different ports"
- "Total connection count and data volume"

**Performance Talking Points:**
1. **Columnar Format**
   - "Parquet columnar storage means we only read the columns we need"
   - "75% compression ratio - 356MB down to 89MB"

2. **Query Engine**
   - "Dremio provides query acceleration"
   - "Can add Reflections (materialized views) for 10-100x speedup"

3. **Scalability**
   - "This is 100K records, but the architecture scales to billions"
   - "We processed this data at 31,000 records per second"

---

## SECTION 4: Architecture & Benefits (3 minutes)

### Architecture Overview

**[Optional: Show diagram or talk through]**

*"Let me quickly explain the architecture behind this demo:"*

**Components:**
1. **Data Source**: Zeek network logs (but could be any security tool)
2. **Transformation**: Python script converts to OCSF format
3. **Storage**: MinIO (S3-compatible) with Parquet files
4. **Query Engine**: Dremio for SQL analytics
5. **Format**: Apache Parquet (columnar, compressed)

**Data Flow:**
```
Zeek Logs â†’ OCSF Transformation â†’ Parquet â†’ MinIO â†’ Dremio â†’ Analysis
```

---

### Key Benefits Demonstrated

**1. Vendor Neutrality**
- "We used Zeek, but the OCSF format works with ANY network security tool"
- "Switch vendors without rewriting queries"
- "Mix and match tools from different vendors"

**2. Performance**
- "Sub-second queries on 100,000 events"
- "Scales to millions/billions with same architecture"
- "75% storage compression"

**3. Open Standards**
- "OCSF is open source and community-driven"
- "Not locked into proprietary formats"
- "Future-proof investment"

**4. Cost Efficiency**
- "S3 storage is cheap (pennies per GB)"
- "No vendor licensing for data format"
- "Open source tools (Zeek, Dremio, MinIO)"

**5. Analyst Productivity**
- "Standard field names across all data sources"
- "No more field mapping guesswork"
- "Queries work across vendors"

---

### Production Readiness

*"This isn't just a demo - this architecture is production-ready:"*

**Proven at Scale:**
- "AWS Security Lake uses OCSF with this exact approach"
- "Validated by major security vendors"
- "Billions of events in production deployments"

**Production Enhancements:**
- Add Dremio Reflections (10-100x speedup)
- Real-time streaming ingestion
- Multiple data sources (Zeek, Suricata, firewalls, cloud)
- Role-based access control
- Monitoring and alerting

---

## SECTION 5: Closing & Q&A (2 minutes)

### Key Takeaways

*"Let me summarize the three main points:"*

**1. OCSF Solves Real Problems**
- Vendor lock-in
- Integration complexity
- Analyst productivity

**2. Modern Data Lake Architecture Works**
- Fast performance
- Cost-effective
- Scales to enterprise

**3. This is Production-Ready Today**
- Open standards
- Proven at scale
- Community-backed

---

### Call to Action

**For Security Teams:**
*"Start with one data source. Transform it to OCSF. Build from there. You don't have to rip and replace everything - you can migrate incrementally."*

**For Data Engineers:**
*"The tools are all open source. The format is standardized. You can build this yourself or there are commercial options that support OCSF."*

**For Executives:**
*"This is about reducing vendor lock-in and future-proofing your security infrastructure. OCSF gives you flexibility and cost control."*

---

### Q&A Preparation

**Likely Questions & Answers:**

**Q: "How hard is it to transform our existing logs to OCSF?"**
A: "It depends on the source. I showed Zeek - that took about 6 hours to build the transformation with 100% OCSF compliance. Common sources like Suricata, Palo Alto, AWS CloudTrail have similar complexity. The ROI comes when you add a second, third, fourth data source - each one just works with your existing queries."

**Q: "What about performance at real scale - millions or billions of events?"**
A: "The architecture I showed scales linearly. AWS Security Lake uses this exact approach with billions of events. You'd add partitioning (we're already partitioned by date), use distributed query engines, and implement incremental ingestion. We processed 1M records at 31K records/second on a laptop - production systems are much faster."

**Q: "Is OCSF mature enough for production?"**
A: "Yes. Version 1.0 was released and is stable. AWS Security Lake is built on OCSF. Major vendors like Splunk, Cloudflare, and Palo Alto are committed. The schema is extensible, so you can add custom fields while maintaining compatibility."

**Q: "What's the total cost compared to traditional SIEM?"**
A: "Storage costs are dramatically lower - S3 is pennies per GB versus dollars per GB for proprietary storage. Query costs depend on your engine choice, but open source options like the ones I showed are free. The big savings come from avoiding vendor lock-in and being able to use best-of-breed tools."

**Q: "How do we handle real-time data?"**
A: "The demo showed batch loading, but you can use Kafka for streaming ingestion, transform in real-time with Spark Structured Streaming, and write to Iceberg tables. Dremio can query the data as it arrives. Sub-second latency is achievable."

**Q: "What if OCSF doesn't have a field we need?"**
A: "OCSF is extensible. You can add custom fields while maintaining compatibility with the standard fields. The schema has extension points designed for this. You get the benefits of standardization for common fields, plus flexibility for unique requirements."

---

## ðŸŽ¯ Demo Success Criteria

After the demo, audience should understand:

âœ… **What OCSF is** - Open standard for security data
âœ… **Why it matters** - Solves vendor lock-in and integration complexity
âœ… **That it works** - Real data, real queries, real performance
âœ… **It's production-ready** - Not just a prototype
âœ… **How to get started** - Open source, community-backed

---

## ðŸ“Š Metrics to Emphasize

Throughout the demo, reinforce these numbers:

- **100,000 records** - Real production-scale data
- **<1 second** - Query response time
- **61 OCSF fields** - Complete implementation
- **100% compliance** - All OCSF validation checks pass
- **75% compression** - Storage efficiency
- **31,250 records/sec** - Processing throughput

---

## ðŸŽ¨ Presentation Tips

### Delivery Style
- **Confident but not arrogant** - "This works" not "This is the only way"
- **Problem-focused** - Start with pain points audience feels
- **Show don't tell** - Live demos beat slides
- **Honest about limitations** - "UI folder browsing is slow, but queries are fast"

### Pacing
- **Don't rush queries** - Let results sink in
- **Pause for questions** - After each major section
- **Watch the clock** - 15 minutes goes fast
- **Have backup queries** - In case one fails

### Technical Preparation
- **Test EVERYTHING beforehand** - Run all queries
- **Have backup browser** - In case of crash
- **Know your credentials** - But don't show password
- **Close unnecessary apps** - Reduce distraction

### Handling Issues
- **Query fails**: "That's why we test in production! Let me try the alternate syntax..."
- **Slow query**: "Interesting - this might be a cold start. Notice how the second run will be faster..."
- **Browser crash**: "That's demo gods testing us. Good thing I have a backup window..."

---

## ðŸš€ Post-Demo Follow-Up

### Materials to Share
1. **GitHub repo** - If you make this public
2. **OCSF documentation** - https://schema.ocsf.io
3. **Setup guide** - Your working configuration
4. **SQL queries** - DEMO-SQL-QUERIES.md

### Next Steps for Interested Parties
1. **Pilot project** - Pick one data source to convert
2. **Architecture review** - Discuss their specific needs
3. **POC planning** - 2-4 week proof of concept
4. **Community connection** - OCSF Slack/GitHub

---

**You're ready to demo! ðŸŽ‰**

This demo proves OCSF + modern data lakes = fast, flexible, future-proof security analytics.